+ 整段音频的解码播放暂停
+ 分段音频能够结合起来播放暂停
+ 音频播放能够同步解码
+ 解码分为两种（这里只兼容 chrome 和 firefox，并针对进行不同的解码方式）
+ 能够添加音效
+ 能够添加环境音效
+ 录音与播放
+ 生成音频文件
+ 音频文件的扩展等
+ 音频的循环，等 
+ 音量大小
+ 音量渐变

## 现在的思路
对于音频的 source 现在应该分为两种形式，一种为完整的资源，可以通过 createBufferSource 来对资源进行控制，
一种为大的音频资源，如何通过分段传输的形式加载，应该采用 createMediaElementSource 来创建 source

经过测试，MediaElement 会被 audioContext 接管，所以响应的音效也能够添加上，有些还待测试，但是也能调用 element 的
接口，所有很大一分部的工作量都在于兼容两套接口，进行统一的封装

所以在内部核心要分为两套，独立开发，需要一个基础类，来提供 audioContext 相关的方法（包括兼容等）
至于原先通过合并 arrayBuffer 来做，这种思路的局限性的兼容与很大的内存消耗，不可取